# ðŸ“Š Ollama Benchmark RAM/VRAM

Este projeto permite medir **tempo de execuÃ§Ã£o**, **uso de RAM** e **uso de VRAM (GPU)** de diferentes modelos rodando no [Ollama](https://ollama.com).  
Ele roda benchmarks em **melhor de N rodadas** (default: 3), salvando os resultados em CSVs e exibindo tabelas no Jupyter/VSCode.

---

## ðŸš€ Funcionalidades

- Mede **tempo total de execuÃ§Ã£o** (`elapsed_wall_sec`) de cada modelo.  
- Mede **pico de RAM** (MB) usado pelo processo do Ollama.  
- Mede **pico de VRAM (Î” MB)** alocado na GPU durante a geraÃ§Ã£o.  
- Executa cada teste em **N rodadas** (configurÃ¡vel).  
- Suporte a **Cold Start** opcional: descarrega o modelo da memÃ³ria entre rodadas, para medir custo de carregamento.  
- Exporta resultados em arquivos CSV para anÃ¡lise posterior.  
- Mostra uma prÃ©via da saÃ­da do modelo (`output_preview`) para cada rodada.

---

## ðŸ“¦ DependÃªncias

VocÃª precisa ter instalado:

- **Python 3.9+**
- **Bibliotecas Python**:
  ```bash
  pip install ollama pandas psutil pynvml
